{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Does adding more data make our sentiment classifier more accurate?\n",
                "\n",
                "Last time we were working with around tens of thousands of tweets to determine if we could figure predict whether a tweet was positive or negative. We weren't necessarily impressed with our performance - our best classifier hit around 75% accuracy. That means one out of four results is wrong!\n",
                "\n",
                "We'd like to think that **the more examples our classifier sees, the better it'll perform**. Let's upgrade our selection to 500,000! We'll be using the same dataset from [Sentiment140](http://www.sentiment140.com/)."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<p class=\"reading-options\">\n  <a class=\"btn\" href=\"/investigating-sentiment-analysis/more-data-to-train-our-sentiment-analysis-tool\">\n    <i class=\"fa fa-sm fa-book\"></i>\n    Read online\n  </a>\n  <a class=\"btn\" href=\"/investigating-sentiment-analysis/notebooks/More data to train our sentiment analysis tool.ipynb\">\n    <i class=\"fa fa-sm fa-download\"></i>\n    Download notebook\n  </a>\n  <a class=\"btn\" href=\"https://colab.research.google.com/github/littlecolumns/ds4j-notebooks/blob/master/investigating-sentiment-analysis/notebooks/More data to train our sentiment analysis tool.ipynb\" target=\"_new\">\n    <i class=\"fa fa-sm fa-laptop\"></i>\n    Interactive version\n  </a>\n</p>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Prep work: Downloading necessary files\n",
                "Before we get started, we need to download all of the data we'll be using.\n",
                "* **sentiment140-subset.csv:** cleaned subset of Sentiment140 data - half a million tweets marked as positive or negative\n"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "# Make data directory if it doesn't exist\n",
                "!mkdir -p data\n",
                "!wget -nc https://nyc3.digitaloceanspaces.com/ml-files-distro/v1/investigating-sentiment-analysis/data/sentiment140-subset.csv.zip -P data\n",
                "!unzip -n -d data data/sentiment140-subset.csv.zip"
            ],
            "outputs": [],
            "execution_count": null
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>polarity</th>\n",
                            "      <th>text</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0</td>\n",
                            "      <td>@kconsidder You never tweet</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0</td>\n",
                            "      <td>Sick today  coding from the couch.</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>1</td>\n",
                            "      <td>@ChargerJenn Thx for answering so quick,I was ...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>1</td>\n",
                            "      <td>Wii fit says I've lost 10 pounds since last ti...</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0</td>\n",
                            "      <td>@MrKinetik Not a thing!!!  I don't really have...</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   polarity                                               text\n",
                            "0         0                      @kconsidder You never tweet  \n",
                            "1         0                 Sick today  coding from the couch.\n",
                            "2         1  @ChargerJenn Thx for answering so quick,I was ...\n",
                            "3         1  Wii fit says I've lost 10 pounds since last ti...\n",
                            "4         0  @MrKinetik Not a thing!!!  I don't really have..."
                        ]
                    },
                    "execution_count": 1,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "import pandas as pd\n",
                "\n",
                "df = pd.read_csv(\"data/sentiment140-subset.csv\")\n",
                "df.head()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "(500000, 2)"
                        ]
                    },
                    "execution_count": 2,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.shape"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "Polarity is `0` for negative, or `1` for positive. We should have roughly equal numbers of each."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "0    250275\n",
                            "1    249725\n",
                            "Name: polarity, dtype: int64"
                        ]
                    },
                    "execution_count": 3,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "df.polarity.value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Extracting our features\n",
                "\n",
                "Just like last time, we're going to use a `TfidfVectorizer` to count our words. It does a little more than count words - it pays less attention to popular words, and makes adjustments for short vs long tweets - but that's the general idea.\n",
                "\n",
                "Last time we only looked at 1000 words, but more words has to help, too, right? **Let's increase the number of words we're examining to 3000.**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>00</th>\n",
                            "      <th>000</th>\n",
                            "      <th>09</th>\n",
                            "      <th>10</th>\n",
                            "      <th>100</th>\n",
                            "      <th>1000</th>\n",
                            "      <th>11</th>\n",
                            "      <th>12</th>\n",
                            "      <th>13</th>\n",
                            "      <th>14</th>\n",
                            "      <th>...</th>\n",
                            "      <th>youu</th>\n",
                            "      <th>yr</th>\n",
                            "      <th>yrs</th>\n",
                            "      <th>yu</th>\n",
                            "      <th>yuck</th>\n",
                            "      <th>yum</th>\n",
                            "      <th>yummy</th>\n",
                            "      <th>yup</th>\n",
                            "      <th>zoo</th>\n",
                            "      <th>\u00bds</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.336949</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.000000</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows \u00d7 3000 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "    00  000   09        10  100  1000   11   12   13   14  ...  youu   yr  \\\n",
                            "0  0.0  0.0  0.0  0.000000  0.0   0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   \n",
                            "1  0.0  0.0  0.0  0.000000  0.0   0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   \n",
                            "2  0.0  0.0  0.0  0.000000  0.0   0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   \n",
                            "3  0.0  0.0  0.0  0.336949  0.0   0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   \n",
                            "4  0.0  0.0  0.0  0.000000  0.0   0.0  0.0  0.0  0.0  0.0  ...   0.0  0.0   \n",
                            "\n",
                            "   yrs   yu  yuck  yum  yummy  yup  zoo   \u00bds  \n",
                            "0  0.0  0.0   0.0  0.0    0.0  0.0  0.0  0.0  \n",
                            "1  0.0  0.0   0.0  0.0    0.0  0.0  0.0  0.0  \n",
                            "2  0.0  0.0   0.0  0.0    0.0  0.0  0.0  0.0  \n",
                            "3  0.0  0.0   0.0  0.0    0.0  0.0  0.0  0.0  \n",
                            "4  0.0  0.0   0.0  0.0    0.0  0.0  0.0  0.0  \n",
                            "\n",
                            "[5 rows x 3000 columns]"
                        ]
                    },
                    "execution_count": 4,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "from sklearn.feature_extraction.text import TfidfVectorizer\n",
                "\n",
                "vectorizer = TfidfVectorizer(max_features=3000)\n",
                "vectors = vectorizer.fit_transform(df.text)\n",
                "words_df = pd.DataFrame(vectors.toarray(), columns=vectorizer.get_feature_names())\n",
                "words_df.head()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Training our models\n",
                "\n",
                "We'll need to figure out **what we're predicting**, and what we're **using to predict**. We're going to be using **words** to predict **polarity**. Let's assign these to the variable names that all data people seem to use."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [],
            "source": [
                "X = words_df\n",
                "y = df.polarity"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "We know whether every one of these tweets is positive or negative, but the algorithms don't! Not yet, anyway.\n",
                "\n",
                "To test how well each algorithm performs, we're going to use some of the tweets to teach the algo and keep some of them secret to test it later."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Picking our algorithms\n",
                "\n",
                "Last time we used four different algorithms:\n",
                "    \n",
                "* `LogisticRegression`\n",
                "* `RandomForestClassifier`\n",
                "* `LinearSVC`\n",
                "* `MultinomialNB`\n",
                "\n",
                "We have no idea how they work, but we did notice a difference: even if they all had about a 70-75% accuracy rate, the time it took to train them was very very different!\n",
                "\n",
                "WIth around tens of thousands tweets our `LogisticRegression` and `RandomForestClassifier` both took well over a minute. We can only imagine it would be much much worse with 500,000, so let's set them aside for now.\n",
                "\n",
                "The other two - `LinearSVC` and `MultinominalNB` - both took under a second with our original dataset, so we can hopefully trust them to not take years this new, larger set."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.svm import LinearSVC\n",
                "from sklearn.naive_bayes import MultinomialNB"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 13.3 s, sys: 13.2 s, total: 26.5 s\n",
                        "Wall time: 34.9 s\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
                            "          intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
                            "          multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
                            "          verbose=0)"
                        ]
                    },
                    "execution_count": 8,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "svc = LinearSVC()\n",
                "svc.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "CPU times: user 12.1 s, sys: 23.9 s, total: 36.1 s\n",
                        "Wall time: 36.2 s\n"
                    ]
                },
                {
                    "data": {
                        "text/plain": [
                            "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
                        ]
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "%%time\n",
                "bayes = MultinomialNB()\n",
                "bayes.fit(X_train, y_train)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Analyzing their performance\n",
                "\n",
                "We'll use a confusion matrix to see how well each algorithm them performed. Last time we hit around 70-75% accuracy after training on a few tens of thousands of tweets. What kind of impact does upgrading to 15x as many tweets and 3x as many words have?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.metrics import confusion_matrix"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### SVC"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Predicted negative</th>\n",
                            "      <th>Predicted positive</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>Is negative</th>\n",
                            "      <td>0.767197</td>\n",
                            "      <td>0.235177</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>Is positive</th>\n",
                            "      <td>0.197144</td>\n",
                            "      <td>0.800846</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "             Predicted negative  Predicted positive\n",
                            "Is negative            0.767197            0.235177\n",
                            "Is positive            0.197144            0.800846"
                        ]
                    },
                    "execution_count": 11,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "y_true = y_test\n",
                "y_pred = svc.predict(X_test)\n",
                "matrix = confusion_matrix(y_true, y_pred)\n",
                "\n",
                "label_names = pd.Series(['negative', 'positive'])\n",
                "pd.DataFrame(matrix,\n",
                "     columns='Predicted ' + label_names,\n",
                "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Naive Bayes"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>Predicted negative</th>\n",
                            "      <th>Predicted positive</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>Is negative</th>\n",
                            "      <td>0.768645</td>\n",
                            "      <td>0.233713</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>Is positive</th>\n",
                            "      <td>0.236958</td>\n",
                            "      <td>0.760626</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "             Predicted negative  Predicted positive\n",
                            "Is negative            0.768645            0.233713\n",
                            "Is positive            0.236958            0.760626"
                        ]
                    },
                    "execution_count": 12,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "y_true = y_test\n",
                "y_pred = bayes.predict(X_test)\n",
                "matrix = confusion_matrix(y_true, y_pred)\n",
                "\n",
                "label_names = pd.Series(['negative', 'positive'])\n",
                "pd.DataFrame(matrix,\n",
                "     columns='Predicted ' + label_names,\n",
                "     index='Is ' + label_names).div(matrix.sum(axis=1), axis=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "In predicting positive tweets, `Linear` won, improving from about ~76% last time to ~79% now. `MultinomialNB` went from around ~72% to ~76%.\n",
                "\n",
                "In predicting negative tweets, though, `MultinomialNB` and `LinearSVC` both hit around ~74-77%, which is just about the same as last time.\n",
                "\n",
                "Note that your numbers might be slightly different! Between the randomized nature of machine learing algorithms and getting a different selection in the test/train split, we're only able to talk about rough estimates of performance."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Review\n",
                "\n",
                "Last time we trained our sentiment analysis algorithms on tens of thousands of tweets, and we hoped that by **increasing the amount of data we analyzed we'd also increase accuracy.** We upgraded to hundreds of thousands of tweets, along with looking at more total words.\n",
                "\n",
                "We only used **two of the faster algorithms** from last time, as the others would probably be too slow to finish in a reasonable amount of time. We still don't know the difference between them, but we're only concerned with the output at the moment.\n",
                "\n",
                "This new approach took much more data and more training time, but it did **improve performance by a few percentage points.** We aren't anywhere near being perfect, though: our best approach successfully predicted 80% of positive tweets."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Discussion topics\n",
                "\n",
                "We grew our dataset by 15x and the vocabulary we were looking at by 3x - were the changes worth it?\n",
                "\n",
                "The worst part about building a classifier is either finding a tagged dataset or building one yourself. In this case we downloaded the tweets from [Sentiment140](http://www.sentiment140.com/) and they were already marked as either positive or negative. If this were \"real life,\" though, we'd probably have to order an army of interns on the task!\n",
                "\n",
                "Sentiment140 tweets were automatically tagged based on the presence of `:)` or `:(` in the tweet. Does this seem reasonable?\n",
                "\n",
                "Is a 4% gain in accuracy worth the tradeoff of having to acquire 15x more data and spend 60x more time training your model? When might it be worth it, and when might it not be?\n",
                "\n",
                "Is 80% accuracy good? Do your feelings change if the performance is described as \"incorrect one out of every five times?\" What would your accuracy be for a random guess?\n",
                "\n",
                "Going from 30k to 500k examples only got us a few percentage points of improvement: do you think this is always the case, or is this something special about tweets? Do you think product reviews would be the same?\n",
                "\n",
                "How should we feel about not understanding what the difference is between the algorithms we're using or casting aside? Is knowing their training time and performance good enough substitute for understanding what's going on inside?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        },
        "toc": {
            "base_numbering": 1,
            "nav_menu": {},
            "number_sections": true,
            "sideBar": true,
            "skip_h1_title": false,
            "title_cell": "Table of Contents",
            "title_sidebar": "Contents",
            "toc_cell": false,
            "toc_position": {},
            "toc_section_display": true,
            "toc_window_display": false
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}