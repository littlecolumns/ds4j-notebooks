{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Breaking down a few different kinds of text analysis\n",
                "\n",
                "Natural language processing (NLP) is a wide wide field that encompasses _everything_ involving language. We'll mostly be sticking with analyzing documents, but even then there are a hundred and one different things we can do. Let's break a few of them down.\n",
                "\n",
                "_(and yes, everything from books to tweets count as \"documents\")_"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "<p class=\"reading-options\">\n  <a class=\"btn\" href=\"/text-analysis/types-of-text-analysis\">\n    <i class=\"fa fa-sm fa-book\"></i>\n    Read online\n  </a>\n  <a class=\"btn\" href=\"/text-analysis/notebooks/Types of text analysis.ipynb\">\n    <i class=\"fa fa-sm fa-download\"></i>\n    Download notebook\n  </a>\n  <a class=\"btn\" href=\"https://colab.research.google.com/github/littlecolumns/ds4j-notebooks/blob/master/text-analysis/notebooks/Types of text analysis.ipynb\" target=\"_new\">\n    <i class=\"fa fa-sm fa-laptop\"></i>\n    Interactive version\n  </a>\n</p>"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Word counting\n",
                "\n",
                "Sometimes you just want to [count some words](/text-analysis/counting-words-with-pythons-counter/). We outline both a simple technique as well as [a more advanced version](/text-analysis/counting-words-with-scikit-learns-countvectorizer/), too.\n",
                "\n",
                "## Topic modeling and clustering\n",
                "\n",
                "If you have no clue what a set of documents might be about, both **topic modeling** and **clustering** are approaches to getting [a glance at what's inside](/text-analysis/topic-modeling-and-clustering). Topic modeling tries to find a set of topics that show up in the documents, while clustering organizes the documents into separate, discrete categories.\n",
                "\n",
                "## Entity extraction\n",
                "\n",
                "Sometimes you aren't looking for concepts, you're looking for **actual people or things**. Who is mentioned in that document dump? What companies are listed in a judge's conflict of interest filings? This is **[entity extraction](/text-analysis/named-entity-recognition/).**\n",
                "\n",
                "## Classification\n",
                "\n",
                "When you have a large set of documents, you can often organize them into two (or more) categories: **ones you're interested in and ones you aren't.**\n",
                "\n",
                "You might be trying to find comments mentioning bullying, or  discplinary orders about sexual abuse, or complaints mentioning airbags that malfunctioned in a specific way. **Classification** can help out in these situations, by having you train the computer what interesting and uninteresting documents look like. You read a portion and then let the computer explore the rest!\n",
                "\n",
                "We cover classification under [a different section](/classification/intro-to-classification/), so you'll want to review how to [count words](/text-analysis/counting-words-with-scikit-learns-countvectorizer/) first.\n",
                "\n",
                "## Sentiment analysis\n",
                "\n",
                "Positive or negative? Happy or sad? [Sentiment analysis](/investigating-sentiment-analysis/comparing-sentiment-analysis-tools/) is the idea that you can extract emotional meaning based on what people have written. Often used for news stories or tweets, it's generally a subset of classification.\n",
                "\n",
                "## Document similarity\n",
                "\n",
                "Comparing two or more documents can be approached a few different ways. Are you looking for word-for-word plagiarism, or just similarity in concepts? The former you can do with [simple counts](/text-analysis/explaining-n-grams-in-natural-language-processing/), while the latter takes [a leap into word embeddings](/text-analysis/document-similarity-using-word-embeddings/)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": []
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        },
        "toc": {
            "base_numbering": 1,
            "nav_menu": {},
            "number_sections": true,
            "sideBar": true,
            "skip_h1_title": false,
            "title_cell": "Table of Contents",
            "title_sidebar": "Contents",
            "toc_cell": false,
            "toc_position": {},
            "toc_section_display": true,
            "toc_window_display": false
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}